---
language: en
license: mit
tags:
- deepfake-detection
- image-classification
- computer-vision
- efficientnet
- attention-mechanism
- synthetic-image-detection
- gan-detection
- diffusion-detection
datasets:
- custom
metrics:
- accuracy
- precision
- recall
- f1
library_name: tensorflow
pipeline_tag: image-classification
---

# DeepFake Detection Model - EfficientNetB7 with Attention Mechanism

**Developed by**: Emin Cem Koyluoglu
**Presented at**: AICS 2025 (33rd Irish Conference on Artificial Intelligence and Cognitive Science)
**License**: MIT
**Framework**: TensorFlow 2.15 / Keras

## Model Description

This is a deep learning model designed to detect AI-generated (synthetic) images and distinguish them from authentic photographs. The model combines the EfficientNetB7 architecture with a custom attention mechanism to achieve robust detection of images generated by various generative AI models including GANs and diffusion models.

### Key Features

- **Binary Classification**: Distinguishes between authentic and AI-generated images
- **High Performance**: Fast inference suitable for real-time applications
- **Robust Detection**: Trained on multiple generative model families
- **Attention Mechanism**: Custom spatial attention for enhanced feature learning
- **Compact Input**: 128Ã—128 pixel input for efficient processing

## Supported Generative Models

The model has been trained to detect synthetic images from:

### Generative Adversarial Networks (GANs)
- StyleGAN (v1, v2, v3)
- ProGAN
- BigGAN
- CycleGAN
- StarGAN
- And other GAN variants

### Diffusion-Based Models
- Stable Diffusion
- DALL-E (2, 3)
- Midjourney
- Imagen
- DDPM, DDIM and other diffusion models

### Other Generative Techniques
- VAE-based generators
- Autoregressive models
- Neural style transfer
- Image-to-image translation systems

## Model Architecture

```
Input (128Ã—128Ã—3 RGB image)
    â†“
EfficientNetB7 Backbone (Pre-trained on ImageNet)
    â†“
Batch Normalization
    â†“
Custom Attention Mechanism
    â”œâ”€â”€ Conv2D (256 filters, 1Ã—1) + ReLU + Dropout(0.5)
    â”œâ”€â”€ Conv2D (128 filters, 1Ã—1) + ReLU
    â”œâ”€â”€ Conv2D (128 filters, 1Ã—1) + ReLU
    â”œâ”€â”€ Conv2D (1 filter, 1Ã—1) + Sigmoid â†’ Attention Maps
    â”œâ”€â”€ Element-wise Multiplication (Features Ã— Attention)
    â””â”€â”€ Global Average Pooling â†’ Weighted Feature Vector
    â†“
Dropout (0.5)
    â†“
Dense (64 units, ReLU, L2 regularization)
    â†“
Dropout (0.25)
    â†“
Dense (2 units, Softmax)
    â†“
Output [P(Fake), P(Real)]
```

### Model Specifications

- **Total Parameters**: ~66M (includes EfficientNetB7 backbone)
- **Trainable Parameters**: ~2M (attention module + classification head)
- **Input Dimensions**: 128 Ã— 128 Ã— 3 (Height Ã— Width Ã— Channels)
- **Output Classes**: 2 (Binary: Fake/Real)
- **Model Size**: ~780 MB (H5 format)
- **Framework**: TensorFlow 2.15 / Keras

## Intended Use

### Primary Use Cases
- Detection of AI-generated images
- Media authentication systems
- Digital forensics applications
- Research in synthetic image detection
- Educational demonstrations

### Out-of-Scope Use
- This model should not be used as the sole arbiter of image authenticity in high-stakes scenarios
- Not designed for video deepfake detection
- Not optimized for detecting manipulated/edited authentic images (only fully synthetic generation)

## How to Use

### Installation

```bash
pip install tensorflow>=2.15.0 huggingface-hub numpy pillow opencv-python
```

### Loading the Model

```python
from huggingface_hub import hf_hub_download
from tensorflow import keras
import numpy as np

# Download model
model_path = hf_hub_download(
    repo_id="CemRoot/deepfake-detection-model",
    filename="best_model_effatt.h5"
)

# Custom objects for loading
def RescaleGAP(tensors):
    return tensors[0] / tensors[1]

# Load model
model = keras.models.load_model(
    model_path,
    custom_objects={'RescaleGAP': RescaleGAP},
    compile=False
)
```

### Inference Example

```python
from PIL import Image
import numpy as np
import cv2

def preprocess_image(image_path):
    """Preprocess image for model input"""
    # Load image
    img = Image.open(image_path).convert('RGB')
    img = np.array(img)

    # Resize to 128x128
    img = cv2.resize(img, (128, 128))

    # Normalize to [0, 1]
    img = img.astype(np.float32) / 255.0

    # Add batch dimension
    img = np.expand_dims(img, axis=0)

    return img

# Preprocess image
image = preprocess_image("path/to/your/image.jpg")

# Make prediction
predictions = model.predict(image)
fake_prob = predictions[0][0]  # Probability of being fake
real_prob = predictions[0][1]  # Probability of being real

# Interpret results
if fake_prob > real_prob:
    print(f"ðŸš¨ FAKE (AI-Generated) - Confidence: {fake_prob*100:.2f}%")
else:
    print(f"âœ… AUTHENTIC (Genuine) - Confidence: {real_prob*100:.2f}%")
```

### Integration with Streamlit

See the [Streamlit Application Repository](https://github.com/CemRoot/deepfake-detection-streamlit) for a complete web interface implementation.

## Training Details

### Training Data
- Large-scale dataset of authentic photographs
- Synthetic images from multiple generative model families
- Balanced distribution of real and fake images
- Diverse image categories and domains

### Training Procedure
- **Optimizer**: Adam
- **Loss Function**: Categorical Crossentropy
- **Input Size**: 128Ã—128Ã—3 RGB images
- **Preprocessing**: Normalization to [0, 1] range
- **Regularization**: Dropout (0.5, 0.25) and L2 weight regularization
- **Backbone**: EfficientNetB7 (frozen during training)

### Preprocessing

The model expects images preprocessed as follows:
1. Resize to 128Ã—128 pixels
2. Convert to RGB color space
3. Normalize pixel values to [0, 1] range
4. Input shape: (batch_size, 128, 128, 3)

## Performance

### Computational Performance
- **CPU Inference**: 2-3 seconds per image (Intel i5-8250U)
- **GPU Inference**: < 1 second per image (NVIDIA GTX 1060)
- **Memory Usage**: ~2 GB RAM
- **Batch Processing**: Supported for multiple images

### Robustness
The model maintains reliable performance under:
- JPEG compression at various quality levels
- Image resizing and resolution changes
- Format conversion (PNG â†” JPEG)
- Mild post-processing operations
- Partial cropping

## Limitations

### Known Limitations
1. **Emerging Models**: Performance on newly released generative models may vary
2. **Image Quality**: Very low-quality or heavily compressed images may reduce accuracy
3. **Domain Shift**: Performance may vary on images from domains not well-represented in training
4. **Adversarial Attacks**: Not specifically hardened against adversarial perturbations
5. **Hybrid Content**: Images that are partially synthetic/partially authentic may be challenging

### Bias Considerations
- Training data distribution may not represent all demographic groups equally
- Performance may vary across different image categories
- Model has been trained primarily on photographic content

## Ethical Considerations

### Responsible Use
- This model is intended for research, education, and constructive applications
- Should not be used to harass, discriminate, or make unfounded accusations
- Results should be interpreted as probabilistic assessments, not absolute truth
- Consider the broader context when using AI detection systems

### Potential Misuse
- False accusations based solely on model output
- Circumvention of detection through adversarial methods
- Use in contexts requiring human judgment and expertise

## Citation

If you use this model in your research or applications, please cite:

```bibtex
@inproceedings{koyluoglu2025deepfake,
  title={Advanced DeepFake Detection using EfficientNetB7 with Attention Mechanism},
  author={Koyluoglu, Emin Cem},
  booktitle={Proceedings of the 33rd Irish Conference on Artificial Intelligence and Cognitive Science (AICS 2025)},
  year={2025},
  organization={AICS},
  note={Demo presentation}
}
```

## Model Card Authors

Emin Cem Koyluoglu

## Model Card Contact

- **GitHub**: [@CemRoot](https://github.com/CemRoot)
- **Website**: [cemkoyluoglu.codes](https://cemkoyluoglu.codes/)
- **Repository**: [deepfake-detection-streamlit](https://github.com/CemRoot/deepfake-detection-streamlit)

## Additional Resources

- **Live Demo**: [Streamlit Application](https://your-app-url.streamlit.app)
- **Source Code**: [GitHub Repository](https://github.com/CemRoot/deepfake-detection-streamlit)
- **Documentation**: See repository README for detailed information
- **Paper**: AICS 2025 Conference Proceedings (forthcoming)

## Version History

- **v1.0.0** (2025): Initial release
  - EfficientNetB7 + Custom Attention Mechanism
  - Binary classification (Fake/Real)
  - Support for multiple generative model families
  - Deployed on Hugging Face Model Hub

## License

This model is released under the MIT License. See the [LICENSE](https://github.com/CemRoot/deepfake-detection-streamlit/blob/main/LICENSE) file for details.

---

**Built with dedication for advancing media integrity research**

âš¡ Powered by TensorFlow | ðŸ¤— Hosted on Hugging Face | ðŸŽ¯ Application: Digital Forensics
